{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3d3d39ab",
      "metadata": {
        "id": "3d3d39ab"
      },
      "source": [
        "# Intelligent App with Google Generative AI and Neo4j\n",
        "In this notebook, let's explore how to leverage Google GenAI to build and consume a knowledge graph in Neo4j.\n",
        "\n",
        "This notebook parses data from a public [corpus of Resumes / Curriculum Vitae](https://github.com/florex/resume_corpus) using Google Vertex AI Generative AI's `text-bison` model. The model will be prompted to recognise and extract entities and relationships. We will then generate Neo4j Cypher queries using them and write the data to a Neo4j database.\n",
        "We will again use a `text-bison` model and prompt it to convert questions in english to Cypher - Neo4j's query language, which can be used for data retrieval."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f17a9328-f17d-48ae-b72e-c333fb867eb0",
      "metadata": {
        "id": "f17a9328-f17d-48ae-b72e-c333fb867eb0",
        "tags": []
      },
      "source": [
        "## Setup\n",
        "First off, check that the Python environment you installed in the readme is running this notebook. Make sure you select the `py38` kernel in the top right of this notebook. You should see a 3.8 version when you run this command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b97b17-4ec5-447a-88d0-df6faaf662fe",
      "metadata": {
        "id": "80b97b17-4ec5-447a-88d0-df6faaf662fe",
        "outputId": "24d9c962-7a2e-4347-d78e-fdea74fbf36c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import sys\n",
        "sys.version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/neo4j-partners/intelligent-app-google-generativeai-neo4j.git"
      ],
      "metadata": {
        "id": "xKUrHD1hXiMm",
        "outputId": "b421f483-d03f-4143-edaf-514112953f05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xKUrHD1hXiMm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'intelligent-app-google-generativeai-neo4j'...\n",
            "remote: Enumerating objects: 5640, done.\u001b[K\n",
            "remote: Counting objects: 100% (180/180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (123/123), done.\u001b[K\n",
            "remote: Total 5640 (delta 104), reused 127 (delta 57), pack-reused 5460\u001b[K\n",
            "Receiving objects: 100% (5640/5640), 14.77 MiB | 14.37 MiB/s, done.\n",
            "Resolving deltas: 100% (241/241), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87eb2fda-70c8-4733-ac6f-2678e5cbff47",
      "metadata": {
        "id": "87eb2fda-70c8-4733-ac6f-2678e5cbff47"
      },
      "source": [
        "Next we need to install some libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43720d2e-05cd-49de-bbb9-15c0b10d768b",
      "metadata": {
        "id": "43720d2e-05cd-49de-bbb9-15c0b10d768b",
        "outputId": "63beb357-beea-4ef5-8f4b-d57aa5d87334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-cloud-aiplatform>=1.25.0\n",
            "  Downloading google_cloud_aiplatform-1.26.0-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform>=1.25.0) (2.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform>=1.25.0) (1.22.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform>=1.25.0) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform>=1.25.0) (23.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform>=1.25.0) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform>=1.25.0) (3.9.0)\n",
            "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform>=1.25.0)\n",
            "  Downloading google_cloud_resource_manager-1.10.1-py2.py3-none-any.whl (321 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.3/321.3 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shapely<2.0.0 (from google-cloud-aiplatform>=1.25.0)\n",
            "  Downloading Shapely-1.8.5.post1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (2.27.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (1.54.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (1.48.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.25.0) (2.3.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.25.0) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.25.0) (2.8.2)\n",
            "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform>=1.25.0)\n",
            "  Downloading grpc_google_iam_v1-0.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.25.0) (1.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (3.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.25.0) (0.5.0)\n",
            "Installing collected packages: shapely, grpc-google-iam-v1, google-cloud-resource-manager, google-cloud-aiplatform\n",
            "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed google-cloud-aiplatform-1.26.0 google-cloud-resource-manager-1.10.1 grpc-google-iam-v1-0.12.6 shapely-1.8.5.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-cloud-aiplatform[pipelines]>=1.25.0 in /root/.local/lib/python3.10/site-packages (1.26.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform[pipelines]>=1.25.0) (2.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform[pipelines]>=1.25.0) (1.22.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform[pipelines]>=1.25.0) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform[pipelines]>=1.25.0) (23.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform[pipelines]>=1.25.0) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform[pipelines]>=1.25.0) (3.9.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /root/.local/lib/python3.10/site-packages (from google-cloud-aiplatform[pipelines]>=1.25.0) (1.10.1)\n",
            "Requirement already satisfied: shapely<2.0.0 in /root/.local/lib/python3.10/site-packages (from google-cloud-aiplatform[pipelines]>=1.25.0) (1.8.5.post1)\n",
            "Collecting pyyaml<6,>=5.3 (from google-cloud-aiplatform[pipelines]>=1.25.0)\n",
            "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (2.27.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (1.54.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (1.48.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform[pipelines]>=1.25.0) (2.3.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform[pipelines]>=1.25.0) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform[pipelines]>=1.25.0) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /root/.local/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform[pipelines]>=1.25.0) (0.12.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform[pipelines]>=1.25.0) (1.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (3.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform[pipelines]>=1.25.0) (0.5.0)\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.4.1-cp310-cp310-linux_x86_64.whl size=45658 sha256=4da82e1402f899e83c45daf9d91c0bb3020cd20eb3e8a781f222494105f24ca7\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/0d/22/696ee92245ad710f506eee79bb05c740d8abccd3ecdb778683\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "Successfully installed pyyaml-5.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain==0.0.198\n",
            "  Downloading langchain-0.0.198-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /root/.local/lib/python3.10/site-packages (from langchain==0.0.198) (5.4.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.198) (2.0.10)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.0.198)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain==0.0.198)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.198)\n",
            "  Downloading dataclasses_json-0.5.8-py3-none-any.whl (26 kB)\n",
            "Collecting langchainplus-sdk>=0.0.7 (from langchain==0.0.198)\n",
            "  Downloading langchainplus_sdk-0.0.10-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.198) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.198) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.198)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.198) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.198) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.198) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.198) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.198) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.198)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.198)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.198)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.198)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.198)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.198)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.198)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.198) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.198) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.198) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.198) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.198) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.198) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.198)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, aiosignal, dataclasses-json, aiohttp, langchain\n",
            "\u001b[33m  WARNING: The script langchain is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.8 frozenlist-1.3.3 langchain-0.0.198 langchainplus-sdk-0.0.10 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neo4j\n",
            "  Downloading neo4j-5.9.0.tar.gz (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2022.7.1)\n",
            "Building wheels for collected packages: neo4j\n",
            "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neo4j: filename=neo4j-5.9.0-py3-none-any.whl size=259467 sha256=4794ea965de931140c79b2984efd848f50ed3683c2d246e8e677e869454f3688\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/d6/e2/3534952aaddb39337f01f3fd66b3f3f2dd65051306a614af92\n",
            "Successfully built neo4j\n",
            "Installing collected packages: neo4j\n",
            "Successfully installed neo4j-5.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (1.10.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.34.0-py3-none-any.whl (20.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from gradio)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: aiohttp in /root/.local/lib/python3.10/site-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.97.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.6 (from gradio)\n",
            "  Downloading gradio_client-0.2.7-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.4/288.4 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Collecting orjson (from gradio)\n",
            "  Downloading orjson-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.7)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /root/.local/lib/python3.10/site-packages (from gradio) (5.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Collecting semantic-version (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.6->gradio) (2023.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.6->gradio) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /root/.local/lib/python3.10/site-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /root/.local/lib/python3.10/site-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /root/.local/lib/python3.10/site-packages (from aiohttp->gradio) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /root/.local/lib/python3.10/site-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /root/.local/lib/python3.10/site-packages (from aiohttp->gradio) (1.3.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.15)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=cb84099694a2bbba0e29a06b048b6be9cf57a144c147635a9be33156b3a2e2f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, h11, aiofiles, uvicorn, starlette, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "\u001b[33m  WARNING: The script uvicorn is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script huggingface-cli is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script httpx is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts gradio and upload_theme are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.1.0 fastapi-0.97.0 ffmpy-0.3.0 gradio-3.34.0 gradio-client-0.2.7 h11-0.14.0 httpcore-0.17.2 httpx-0.24.1 huggingface-hub-0.15.1 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 orjson-3.9.1 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting IProgress\n",
            "  Downloading IProgress-0.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from IProgress) (1.16.0)\n",
            "Installing collected packages: IProgress\n",
            "Successfully installed IProgress-0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install --user \"google-cloud-aiplatform>=1.25.0\" --upgrade\n",
        "%pip install --user \"google-cloud-aiplatform[pipelines]>=1.25.0\"\n",
        "%pip install --user \"langchain==0.0.198\"\n",
        "%pip install --user neo4j\n",
        "%pip install --user pydantic\n",
        "%pip install --user gradio\n",
        "%pip install --user IProgress\n",
        "%pip install --user tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42f91036-7018-465f-b4af-8d5523e7ed3a",
      "metadata": {
        "id": "42f91036-7018-465f-b4af-8d5523e7ed3a"
      },
      "source": [
        "Now restart the kernel.  That will allow the Python evironment to import the new packages."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a44ccbf1-28bf-48cc-969f-30932ad9bd95",
      "metadata": {
        "id": "a44ccbf1-28bf-48cc-969f-30932ad9bd95"
      },
      "source": [
        "Provide your `Project ID` (**NOT** Project Name) & `location` in the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ad823ee-84ca-4de3-9b29-4b324ac5b9ae",
      "metadata": {
        "id": "4ad823ee-84ca-4de3-9b29-4b324ac5b9ae"
      },
      "outputs": [],
      "source": [
        "# Note, you will need to set your project_id\n",
        "project_id = 'workshop-trvlk'\n",
        "location = 'us-central1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42c5a70c-aee1-462b-953a-4c87a524a111",
      "metadata": {
        "id": "42c5a70c-aee1-462b-953a-4c87a524a111"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "vertexai.init(project=project_id, location='us-central1')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e43bb3c",
      "metadata": {
        "id": "4e43bb3c"
      },
      "source": [
        "## Prompt Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72960046",
      "metadata": {
        "id": "72960046"
      },
      "source": [
        "In the upcoming sections, we will extract knowledge adhering to the following schema. This is a very Simplified schema to denote a Resume. Normally, you will have Domain Experts who come up with an ideal Ontology."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2599f51b-aa46-471e-be3f-2544124dae3d",
      "metadata": {
        "id": "2599f51b-aa46-471e-be3f-2544124dae3d"
      },
      "source": [
        "![schema.png](attachment:4bb6059e-7375-4dd2-99cd-f3142706d6e9.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7781a12b",
      "metadata": {
        "id": "7781a12b"
      },
      "source": [
        "To achieve our Extraction goal as per the schema, I am going to chain a series of prompts, each focused on only one task - to extract a specific entity. By this way, you can avoid Token limitations. Also, the quality of extraction will be good."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7921fa85",
      "metadata": {
        "id": "7921fa85"
      },
      "outputs": [],
      "source": [
        "person_prompt_tpl=\"\"\"From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
        "1. First, look for the Person Entity type in the text and extract the needed information defined below:\n",
        "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Person entity under `description` property\n",
        "    Entity Types:\n",
        "    label:'Person',id:string,role:string,description:string //Person Node\n",
        "2. Description property should be a crisp text summary and MUST NOT be more than 100 characters\n",
        "3. If you cannot find any information on the entities & relationships above, it is okay to return empty value. DO NOT create fictious data\n",
        "4. Do NOT create duplicate entities\n",
        "5. Restrict yourself to extract only Person information. No Position, Company, Education or Skill information should be focussed.\n",
        "6. NEVER Impute missing values\n",
        "Example Output JSON:\n",
        "{\"entities\": [{\"label\":\"Person\",\"id\":\"person1\",\"role\":\"Prompt Developer\",\"description\":\"Prompt Developer with more than 30 years of LLM experience\"}]}\n",
        "\n",
        "Question: Now, extract the Person for the text below -\n",
        "$ctext\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d903cb98-ce84-43bb-b860-71a394604a52",
      "metadata": {
        "id": "d903cb98-ce84-43bb-b860-71a394604a52"
      },
      "outputs": [],
      "source": [
        "postion_prompt_tpl=\"\"\"From the Resume text for a job aspirant below, extract Entities & relationships strictly as instructed below\n",
        "1. First, look for Position & Company types in the text and extract information in comma-separated format. Position Entity denotes the Person's previous or current job. Company node is the Company where they held that position.\n",
        "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
        "    Entity Types:\n",
        "    label:'Position',id:string,title:string,location:string,startDate:string,endDate:string,url:string //Position Node\n",
        "    label:'Company',id:string,name:string //Company Node\n",
        "2. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. NEVER create new Relationship types that aren't mentioned below:\n",
        "    Relationship definition:\n",
        "    position|AT_COMPANY|company //Ensure this is a string in the generated output\n",
        "3. If you cannot find any information on the entities & relationships above, it is okay to return empty value. DO NOT create fictious data\n",
        "4. Do NOT create duplicate entities.\n",
        "5. No Education or Skill information should be extracted.\n",
        "6. DO NOT MISS out any Position or Company related information\n",
        "7. NEVER Impute missing values\n",
        " Example Output JSON:\n",
        "{\"entities\": [{\"label\":\"Position\",\"id\":\"position1\",\"title\":\"Software Engineer\",\"location\":\"Singapore\",startDate:\"2021-01-01\",endDate:\"present\"},{\"label\":\"Position\",\"id\":\"position2\",\"title\":\"Senior Software Engineer\",\"location\":\"Mars\",startDate:\"2020-01-01\",endDate:\"2020-12-31\"},{label:\"Company\",id:\"company1\",name:\"Neo4j Singapore Pte Ltd\"},{\"label\":\"Company\",\"id\":\"company2\",\"name\":\"Neo4j Mars Inc\"}],\"relationships\": [\"position1|AT_COMPANY|company1\",\"position2|AT_COMPANY|company2\"]}\n",
        "\n",
        "Question: Now, extract entities & relationships as mentioned above for the text below -\n",
        "$ctext\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffdf7091-20ff-4537-9aa8-b96a9325b2a6",
      "metadata": {
        "id": "ffdf7091-20ff-4537-9aa8-b96a9325b2a6"
      },
      "outputs": [],
      "source": [
        "skill_prompt_tpl=\"\"\"From the Resume text below, extract Entities strictly as instructed below\n",
        "1. Look for prominent Skill Entities in the text. The`id` property of each entity must be alphanumeric and must be unique among the entities. NEVER create new entity types that aren't mentioned below:\n",
        "    Entity Definition:\n",
        "    label:'Skill',id:string,name:string,level:string //Skill Node\n",
        "2. NEVER Impute missing values\n",
        "3. If you do not find any level information: assume it as `expert` if the experience in that skill is more than 5 years, `intermediate` for 2-5 years and `beginner` otherwise.\n",
        "Example Output Format:\n",
        "{\"entities\": [{\"label\":\"Skill\",\"id\":\"skill1\",\"name\":\"Neo4j\",\"level\":\"expert\"},{\"label\":\"Skill\",\"id\":\"skill2\",\"name\":\"Pytorch\",\"level\":\"expert\"}]}\n",
        "\n",
        "Question: Now, extract entities as mentioned above for the text below -\n",
        "$ctext\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e188d63a-1a13-4363-8917-1af3123cbda1",
      "metadata": {
        "id": "e188d63a-1a13-4363-8917-1af3123cbda1"
      },
      "outputs": [],
      "source": [
        "edu_prompt_tpl=\"\"\"From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
        "1. Look for Education entity type and generate the information defined below:\n",
        "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create other entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
        "    Entity Definition:\n",
        "    label:'Education',id:string,degree:string,university:string,graduationDate:string,score:string,url:string //Education Node\n",
        "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictious data\n",
        "3. Do NOT create duplicate entities or properties\n",
        "4. Strictly extract only Education. No Skill or other Entities should be extracted\n",
        "5. DO NOT MISS out any Education related entity\n",
        "6. NEVER Impute missing values\n",
        "Output JSON (Strict):\n",
        "{\"entities\": [{\"label\":\"Education\",\"id\":\"education1\",\"degree\":\"Bachelor of Science\",\"graduationDate\":\"May 2022\",\"score\":\"0.0\"}]}\n",
        "\n",
        "Question: Now, extract Education information as mentioned above for the text below -\n",
        "$ctext\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate with Google Cloud credentials\n",
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "Tc-dCi-uRLJq"
      },
      "id": "Tc-dCi-uRLJq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "605ad98c",
      "metadata": {
        "id": "605ad98c"
      },
      "source": [
        "This is a helper function to talk to the LLM with our prompt and text input. We will use the `text-bison` base model. In your usecase, you might need to tune it. VertexAI provides an elegant way to finetune it. The weights will be staying within your tenant and the base model is frozen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1148d87e",
      "metadata": {
        "id": "1148d87e"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "\n",
        "def run_text_model(\n",
        "    project_id: str,\n",
        "    model_name: str,\n",
        "    temperature: float,\n",
        "    max_decode_steps: int,\n",
        "    top_p: float,\n",
        "    top_k: int,\n",
        "    prompt: str,\n",
        "    location: str = \"us-central1\",\n",
        "    tuned_model_name: str = \"\",\n",
        "    ) :\n",
        "    \"\"\"Text Completion Use a Large Language Model.\"\"\"\n",
        "    vertexai.init(project=project_id, location=location)\n",
        "    model = TextGenerationModel.from_pretrained(model_name)\n",
        "    if tuned_model_name:\n",
        "      model = model.get_tuned_model(tuned_model_name)\n",
        "    response = model.predict(\n",
        "        prompt,\n",
        "        temperature=temperature,\n",
        "        max_output_tokens=max_decode_steps,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,)\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcbfd725",
      "metadata": {
        "id": "dcbfd725"
      },
      "outputs": [],
      "source": [
        "def extract_entities_relationships(prompt, tuned_model_name):\n",
        "    try:\n",
        "        res = run_text_model(project_id, \"text-bison@001\", 0, 1024, 0.8, 40, prompt, location, tuned_model_name)\n",
        "        return res\n",
        "    except Exception as e:\n",
        "        print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcf22363-093f-4dd3-b882-7e10f0d5e6e4",
      "metadata": {
        "id": "fcf22363-093f-4dd3-b882-7e10f0d5e6e4"
      },
      "source": [
        "Now, let's run our extraction task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95c9cfd6-93db-46a5-bcdc-46abacde65c0",
      "metadata": {
        "id": "95c9cfd6-93db-46a5-bcdc-46abacde65c0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "    return re.sub(r'[^\\x00-\\x7F]+',' ', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6JKeHYgb4op-",
      "metadata": {
        "id": "6JKeHYgb4op-"
      },
      "outputs": [],
      "source": [
        "from string import Template\n",
        "import json\n",
        "\n",
        "sample_que = \"\"\"Developer <span class=\"hl\">Developer</span> Developer - TATA CONSULTANTCY SERVICE Batavia, OH Relevant course work† Database Systems, Database Administration, Database Security & Auditing, Computer Security,Computer Networks, Programming & Software Development, IT, Information Security Concept & Admin,† IT System Acquisition & Integration, Advanced Web Development, and Ethical Hacking: Network Security & Pen Testing. Work Experience Developer TATA CONSULTANTCY SERVICE June 2016 to Present MRM (Government of ME, RI, MS) Developer†††† Working with various technologies such as Java, JSP, JSF, DB2(SQL), LDAP, BIRT report, Jazz version control, Squirrel SQL client, Hibernate, CSS, Linux, and Windows. Work as part of a team that provide support to enterprise applications. Perform miscellaneous support activities as requested by Management. Perform in-depth research and identify sources of production issues.†† SPLUNK Developer† Supporting the Splunk Operational environment for Business Solutions Unit aiming to support overall business infrastructure. Developing Splunk Queries to generate the report, monitoring, and analyzing machine generated big data for server that has been using for onsite and offshore team. Working with Splunk' premium apps such as ITSI, creating services, KPI, and glass tables. Developing app with custom dashboard with front- end ability and advanced XML to serve Business Solution unit' needs. Had in-house app presented at Splunk's .Conf Conference (2016). Help planning, prioritizing and executing development activities. Developer ( front end) intern TOMORROW PICTURES INC - Atlanta, GA April 2015 to January 2016 Assist web development team with multiple front end web technologies and involved in web technologies such as Node.js, express, json, gulp.js, jade, sass, html5, css3, bootstrap, WordPress.†Testing (manually), version control (GitHub), mock up design and ideas Education MASTER OF SCIENCE IN INFORMATION TECHNOLOGY in INFOTMATION TECHNOLOGY KENNESAW STATE UNIVERSITY - Kennesaw, GA August 2012 to May 2015 MASTER OF BUSINESS ADMINISTRATION in INTERNATIONAL BUSINESS AMERICAN INTER CONTINENTAL UNIVERSITY ATLANTA November 2003 to December 2005 BACHELOR OF ARTS in PUBLIC RELATIONS THE UNIVERSITY OF THAI CHAMBER OF COMMERCE - BANGKOK, TH June 1997 to May 2001 Skills Db2 (2 years), front end (2 years), Java (2 years), Linux (2 years), Splunk (2 years), SQL (3 years) Certifications/Licenses Splunk Certified Power User V6.3 August 2016 to Present CERT-112626 Splunk Certified Power User V6.x May 2017 to Present CERT-168138 Splunk Certified User V6.x May 2017 to Present CERT -181476 Driver's License Additional Information Skills† ∑††††SQL, PL/SQL, Knowledge of Data Modeling, Experience on Oracle database/RDBMS.† ∑††††††††Database experience on Oracle, DB2, SQL Sever, MongoDB, and MySQL.† ∑††††††††Knowledge of tools including Splunk, tableau, and wireshark.† ∑††††††††Knowledge of SCRUM/AGILE and WATERFALL methodologies.† ∑††††††††Web technology included: HTML5, CSS3, XML, JSON, JavaScript, node.js, NPM, GIT, express.js, jQuery, Angular, Bootstrap, and Restful API.† ∑††††††††Working Knowledge in JAVA, J2EE, and PHP.† Operating system Experience included: Windows, Mac OS, Linux (Ubuntu, Mint, Kali)††\"\"\"\n",
        "prompts = [person_prompt_tpl, postion_prompt_tpl, skill_prompt_tpl, edu_prompt_tpl]\n",
        "results = {\"entities\": [], \"relationships\": []}\n",
        "\n",
        "for p in prompts:\n",
        "    _prompt = Template(p).substitute(ctext=clean_text(sample_que))\n",
        "    _extraction = extract_entities_relationships(_prompt, '')\n",
        "    if 'Answer:\\n' in _extraction:\n",
        "        _extraction = _extraction.split('Answer:\\n ')[1]\n",
        "    if _extraction.strip() == '':\n",
        "        continue\n",
        "    try:\n",
        "        _extraction = json.loads(_extraction.replace(\"\\'\", \"'\").replace('`', ''))\n",
        "    except json.JSONDecodeError:\n",
        "        # print(_extraction)\n",
        "        #Temp hack to ignore Skills cut off by token limitation\n",
        "        _extraction = _extraction[:_extraction.rfind(\"}\")+1] + ']}'\n",
        "        _extraction = json.loads(_extraction.replace(\"\\'\", \"'\"))\n",
        "    results[\"entities\"].extend(_extraction[\"entities\"])\n",
        "    if \"relationships\" in _extraction:\n",
        "        results[\"relationships\"].extend(_extraction[\"relationships\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4b37bf-f355-4571-95e1-f307a65483b6",
      "metadata": {
        "id": "df4b37bf-f355-4571-95e1-f307a65483b6"
      },
      "outputs": [],
      "source": [
        "person_id = results[\"entities\"][0][\"id\"]\n",
        "for e in results[\"entities\"][1:]:\n",
        "    if e['label'] == 'Position':\n",
        "        results[\"relationships\"].append(f\"{person_id}|HAS_POSITION|{e['id']}\")\n",
        "    if e['label'] == 'Skill':\n",
        "        results[\"relationships\"].append(f\"{person_id}|HAS_SKILL|{e['id']}\")\n",
        "    if e['label'] == 'Education':\n",
        "        results[\"relationships\"].append(f\"{person_id}|HAS_EDUCATION|{e['id']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4720e425-17fe-41b1-999a-076bbf7a7470",
      "metadata": {
        "id": "4720e425-17fe-41b1-999a-076bbf7a7470"
      },
      "source": [
        "The extracted entities & relationships will look like this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a07624b-a1bb-493e-820a-144841b8a6ac",
      "metadata": {
        "id": "4a07624b-a1bb-493e-820a-144841b8a6ac",
        "outputId": "4cc95670-5f8d-4872-d613-dedc78dfe4a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'entities': [{'label': 'Person',\n",
              "   'id': 'person1',\n",
              "   'role': 'Developer',\n",
              "   'description': 'Developer with 10 years of experience in IT industry'},\n",
              "  {'label': 'Position',\n",
              "   'id': 'position1',\n",
              "   'title': 'Developer',\n",
              "   'location': 'Batavia, OH',\n",
              "   'startDate': '2016-06-01',\n",
              "   'endDate': 'present'},\n",
              "  {'label': 'Company', 'id': 'company1', 'name': 'TATA CONSULTANTCY SERVICE'},\n",
              "  {'label': 'Skill', 'id': 'skill1', 'name': 'SQL', 'level': 'expert'},\n",
              "  {'label': 'Skill', 'id': 'skill2', 'name': 'Java', 'level': 'expert'},\n",
              "  {'label': 'Skill', 'id': 'skill3', 'name': 'Linux', 'level': 'expert'},\n",
              "  {'label': 'Skill', 'id': 'skill4', 'name': 'Splunk', 'level': 'expert'},\n",
              "  {'label': 'Skill', 'id': 'skill5', 'name': 'front end', 'level': 'expert'},\n",
              "  {'label': 'Skill', 'id': 'skill6', 'name': 'Db2', 'level': 'expert'},\n",
              "  {'label': 'Skill', 'id': 'skill7', 'name': 'HTML5', 'level': 'intermediate'},\n",
              "  {'label': 'Skill', 'id': 'skill8', 'name': 'CSS3', 'level': 'intermediate'},\n",
              "  {'label': 'Skill', 'id': 'skill9', 'name': 'XML', 'level': 'intermediate'},\n",
              "  {'label': 'Skill', 'id': 'skill10', 'name': 'JSON', 'level': 'intermediate'},\n",
              "  {'label': 'Skill',\n",
              "   'id': 'skill11',\n",
              "   'name': 'JavaScript',\n",
              "   'level': 'intermediate'},\n",
              "  {'label': 'Skill',\n",
              "   'id': 'skill12',\n",
              "   'name': 'node.js',\n",
              "   'level': 'intermediate'},\n",
              "  {'label': 'Skill', 'id': 'skill13', 'name': 'NPM', 'level': 'intermediate'},\n",
              "  {'label': 'Skill', 'id': 'skill14', 'name': 'GIT', 'level': 'intermediate'},\n",
              "  {'label': 'Skill',\n",
              "   'id': 'skill15',\n",
              "   'name': 'express.js',\n",
              "   'level': 'intermediate'},\n",
              "  {'label': 'Skill',\n",
              "   'id': 'skill16',\n",
              "   'name': 'jQuery',\n",
              "   'level': 'intermediate'},\n",
              "  {'label': 'Skill',\n",
              "   'id': 'skill17',\n",
              "   'name': 'Angular',\n",
              "   'level': 'intermediate'},\n",
              "  {'label': 'Skill',\n",
              "   'id': 'skill18',\n",
              "   'name': 'Bootstrap',\n",
              "   'level': 'intermediate'},\n",
              "  {'label': 'Skill',\n",
              "   'id': 'skill19',\n",
              "   'name': 'Restful API',\n",
              "   'level': 'intermediate'},\n",
              "  {'label': 'Skill', 'id': 'skill20', 'name': 'JAVA', 'level': 'intermediate'},\n",
              "  {'label': 'Skill', 'id': 'skill21', 'name': 'J2EE', 'level': 'intermediate'},\n",
              "  {'label': 'Skill', 'id': 'skill22', 'name': 'PHP', 'level': 'intermediate'},\n",
              "  {'label': 'Skill',\n",
              "   'id': 'skill23',\n",
              "   'name': 'Windows',\n",
              "   'level': 'intermediate'},\n",
              "  {'label': 'Skill',\n",
              "   'id': 'skill24',\n",
              "   'name': 'Mac OS',\n",
              "   'level': 'intermediate'},\n",
              "  {'label': 'Skill',\n",
              "   'id': 'skill25',\n",
              "   'name': 'Linux',\n",
              "   'level': 'intermediate'},\n",
              "  {'label': 'Skill',\n",
              "   'id': 'skill26',\n",
              "   'name': 'Ubuntu',\n",
              "   'level': 'intermediate'},\n",
              "  {'label': 'Skill', 'id': 'skill27', 'name': 'Mint', 'level': 'intermediate'},\n",
              "  {'label': 'Skill', 'id': 'skill28', 'name': 'Kali', 'level': 'intermediate'},\n",
              "  {'label': 'Education',\n",
              "   'id': 'education1',\n",
              "   'degree': 'Bachelor of Arts',\n",
              "   'university': 'THE UNIVERSITY OF THAI CHAMBER OF COMMERCE - BANGKOK, TH',\n",
              "   'graduationDate': 'May 2001',\n",
              "   'score': '0.0'},\n",
              "  {'label': 'Education',\n",
              "   'id': 'education2',\n",
              "   'degree': 'Master of Business Administration',\n",
              "   'university': 'AMERICAN INTER CONTINENTAL UNIVERSITY ATLANTA',\n",
              "   'graduationDate': 'December 2005',\n",
              "   'score': '0.0'},\n",
              "  {'label': 'Education',\n",
              "   'id': 'education3',\n",
              "   'degree': 'Master of Science in Information Technology',\n",
              "   'university': 'KENNESAW STATE UNIVERSITY - Kennesaw, GA',\n",
              "   'graduationDate': 'May 2015',\n",
              "   'score': '0.0'}],\n",
              " 'relationships': ['position1|AT_COMPANY|company1',\n",
              "  'person1|HAS_POSITION|position1',\n",
              "  'person1|HAS_SKILL|skill1',\n",
              "  'person1|HAS_SKILL|skill2',\n",
              "  'person1|HAS_SKILL|skill3',\n",
              "  'person1|HAS_SKILL|skill4',\n",
              "  'person1|HAS_SKILL|skill5',\n",
              "  'person1|HAS_SKILL|skill6',\n",
              "  'person1|HAS_SKILL|skill7',\n",
              "  'person1|HAS_SKILL|skill8',\n",
              "  'person1|HAS_SKILL|skill9',\n",
              "  'person1|HAS_SKILL|skill10',\n",
              "  'person1|HAS_SKILL|skill11',\n",
              "  'person1|HAS_SKILL|skill12',\n",
              "  'person1|HAS_SKILL|skill13',\n",
              "  'person1|HAS_SKILL|skill14',\n",
              "  'person1|HAS_SKILL|skill15',\n",
              "  'person1|HAS_SKILL|skill16',\n",
              "  'person1|HAS_SKILL|skill17',\n",
              "  'person1|HAS_SKILL|skill18',\n",
              "  'person1|HAS_SKILL|skill19',\n",
              "  'person1|HAS_SKILL|skill20',\n",
              "  'person1|HAS_SKILL|skill21',\n",
              "  'person1|HAS_SKILL|skill22',\n",
              "  'person1|HAS_SKILL|skill23',\n",
              "  'person1|HAS_SKILL|skill24',\n",
              "  'person1|HAS_SKILL|skill25',\n",
              "  'person1|HAS_SKILL|skill26',\n",
              "  'person1|HAS_SKILL|skill27',\n",
              "  'person1|HAS_SKILL|skill28',\n",
              "  'person1|HAS_EDUCATION|education1',\n",
              "  'person1|HAS_EDUCATION|education2',\n",
              "  'person1|HAS_EDUCATION|education3']}"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8feb2a60",
      "metadata": {
        "id": "8feb2a60"
      },
      "source": [
        "## Data Ingestion Cypher Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b96efc5",
      "metadata": {
        "id": "0b96efc5"
      },
      "source": [
        "The entities and relationships we got from the LLM have to be transformed to Cypher so we can write them into Neo4j."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "084047d0",
      "metadata": {
        "id": "084047d0"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import re\n",
        "\n",
        "def get_prop_str(prop_dict, _id):\n",
        "    s = []\n",
        "    for key, val in prop_dict.items():\n",
        "      if key != 'label' and key != 'id':\n",
        "         s.append(_id+\".\"+key+' = \"'+str(val).replace('\\\"', '\"').replace('\"', '\\\"')+'\"')\n",
        "    return ' ON CREATE SET ' + ','.join(s)\n",
        "\n",
        "def get_cypher_compliant_var(_id):\n",
        "    s = \"_\"+ re.sub(r'[\\W_]', '', _id).lower() #avoid numbers appearing as firstchar; replace spaces\n",
        "    return s[:20] #restrict variable size\n",
        "\n",
        "def generate_cypher(in_json):\n",
        "    e_map = {}\n",
        "    e_stmt = []\n",
        "    r_stmt = []\n",
        "    e_stmt_tpl = Template(\"($id:$label{id:'$key'})\")\n",
        "    r_stmt_tpl = Template(\"\"\"\n",
        "      MATCH $src\n",
        "      MATCH $tgt\n",
        "      MERGE ($src_id)-[:$rel]->($tgt_id)\n",
        "    \"\"\")\n",
        "    for obj in in_json:\n",
        "      for j in obj['entities']:\n",
        "          props = ''\n",
        "          label = j['label']\n",
        "          id = ''\n",
        "          if label == 'Person':\n",
        "            id = 'p'+str(time.time_ns())\n",
        "          elif label == 'Position':\n",
        "            id = 'j'+str(time.time_ns())\n",
        "          elif label == 'Education':\n",
        "            id = 'e'+str(time.time_ns())\n",
        "          else:\n",
        "                id = get_cypher_compliant_var(j['name'])\n",
        "          if label in ['Person', 'Position', 'Education', 'Skill', 'Company']:\n",
        "            varname = get_cypher_compliant_var(j['id'])\n",
        "            stmt = e_stmt_tpl.substitute(id=varname, label=label, key=id)\n",
        "            e_map[varname] = stmt\n",
        "            e_stmt.append('MERGE '+ stmt + get_prop_str(j, varname))\n",
        "\n",
        "      for st in obj['relationships']:\n",
        "          rels = st.split(\"|\")\n",
        "          src_id = get_cypher_compliant_var(rels[0].strip())\n",
        "          rel = rels[1].strip()\n",
        "          if rel in ['HAS_SKILL', 'HAS_EDUCATION', 'AT_COMPANY', 'HAS_POSITION']: #we ignore other relationships\n",
        "            tgt_id = get_cypher_compliant_var(rels[2].strip())\n",
        "            stmt = r_stmt_tpl.substitute(\n",
        "              src_id=src_id, tgt_id=tgt_id, src=e_map[src_id], tgt=e_map[tgt_id], rel=rel)\n",
        "            r_stmt.append(stmt)\n",
        "\n",
        "    return e_stmt, r_stmt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec143b14",
      "metadata": {
        "id": "ec143b14",
        "outputId": "6f19e6bf-8e80-4918-d2ca-e8fa68d7f9d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MERGE (_person1:Person{id:\\'p1686819653114364669\\'}) ON CREATE SET _person1.role = \"Developer\",_person1.description = \"Developer with 10 years of experience in IT industry\"', 'MERGE (_position1:Position{id:\\'j1686819653114612239\\'}) ON CREATE SET _position1.title = \"Developer\",_position1.location = \"Batavia, OH\",_position1.startDate = \"2016-06-01\",_position1.endDate = \"present\"', 'MERGE (_company1:Company{id:\\'_tataconsultantcyser\\'}) ON CREATE SET _company1.name = \"TATA CONSULTANTCY SERVICE\"', 'MERGE (_skill1:Skill{id:\\'_java\\'}) ON CREATE SET _skill1.name = \"Java\",_skill1.level = \"expert\"', 'MERGE (_skill2:Skill{id:\\'_jsp\\'}) ON CREATE SET _skill2.name = \"JSP\",_skill2.level = \"expert\"', 'MERGE (_skill3:Skill{id:\\'_jsf\\'}) ON CREATE SET _skill3.name = \"JSF\",_skill3.level = \"expert\"', 'MERGE (_skill4:Skill{id:\\'_db2\\'}) ON CREATE SET _skill4.name = \"DB2\",_skill4.level = \"expert\"', 'MERGE (_skill5:Skill{id:\\'_sql\\'}) ON CREATE SET _skill5.name = \"SQL\",_skill5.level = \"expert\"', 'MERGE (_skill6:Skill{id:\\'_ldap\\'}) ON CREATE SET _skill6.name = \"LDAP\",_skill6.level = \"expert\"', 'MERGE (_skill7:Skill{id:\\'_birt\\'}) ON CREATE SET _skill7.name = \"BIRT\",_skill7.level = \"expert\"', 'MERGE (_skill8:Skill{id:\\'_jazz\\'}) ON CREATE SET _skill8.name = \"Jazz\",_skill8.level = \"expert\"', 'MERGE (_skill9:Skill{id:\\'_squirrelsql\\'}) ON CREATE SET _skill9.name = \"Squirrel SQL\",_skill9.level = \"expert\"', 'MERGE (_skill10:Skill{id:\\'_hibernate\\'}) ON CREATE SET _skill10.name = \"Hibernate\",_skill10.level = \"expert\"', 'MERGE (_skill11:Skill{id:\\'_css\\'}) ON CREATE SET _skill11.name = \"CSS\",_skill11.level = \"expert\"', 'MERGE (_skill12:Skill{id:\\'_linux\\'}) ON CREATE SET _skill12.name = \"Linux\",_skill12.level = \"expert\"', 'MERGE (_skill13:Skill{id:\\'_windows\\'}) ON CREATE SET _skill13.name = \"Windows\",_skill13.level = \"expert\"', 'MERGE (_skill14:Skill{id:\\'_splunk\\'}) ON CREATE SET _skill14.name = \"Splunk\",_skill14.level = \"expert\"', 'MERGE (_skill15:Skill{id:\\'_frontend\\'}) ON CREATE SET _skill15.name = \"front end\",_skill15.level = \"expert\"', 'MERGE (_skill16:Skill{id:\\'_nodejs\\'}) ON CREATE SET _skill16.name = \"Node.js\",_skill16.level = \"expert\"', 'MERGE (_skill17:Skill{id:\\'_express\\'}) ON CREATE SET _skill17.name = \"express\",_skill17.level = \"expert\"', 'MERGE (_skill18:Skill{id:\\'_json\\'}) ON CREATE SET _skill18.name = \"json\",_skill18.level = \"expert\"', 'MERGE (_skill19:Skill{id:\\'_gulpjs\\'}) ON CREATE SET _skill19.name = \"gulp.js\",_skill19.level = \"expert\"', 'MERGE (_skill20:Skill{id:\\'_jade\\'}) ON CREATE SET _skill20.name = \"jade\",_skill20.level = \"expert\"', 'MERGE (_skill21:Skill{id:\\'_sass\\'}) ON CREATE SET _skill21.name = \"sass\",_skill21.level = \"expert\"', 'MERGE (_skill22:Skill{id:\\'_html5\\'}) ON CREATE SET _skill22.name = \"html5\",_skill22.level = \"expert\"', 'MERGE (_skill23:Skill{id:\\'_css3\\'}) ON CREATE SET _skill23.name = \"css3\",_skill23.level = \"expert\"', 'MERGE (_skill24:Skill{id:\\'_bootstrap\\'}) ON CREATE SET _skill24.name = \"bootstrap\",_skill24.level = \"expert\"', 'MERGE (_skill25:Skill{id:\\'_wordpress\\'}) ON CREATE SET _skill25.name = \"WordPress\",_skill25.level = \"expert\"', 'MERGE (_skill26:Skill{id:\\'_github\\'}) ON CREATE SET _skill26.name = \"GitHub\",_skill26.level = \"expert\"', 'MERGE (_skill27:Skill{id:\\'_mockup\\'}) ON CREATE SET _skill27.name = \"mock up\",_skill27.level = \"expert\"', 'MERGE (_skill28:Skill{id:\\'_ideas\\'}) ON CREATE SET _skill28.name = \"ideas\",_skill28.level = \"expert\"', 'MERGE (_skill29:Skill{id:\\'_oracle\\'}) ON CREATE SET _skill29.name = \"Oracle\",_skill29.level = \"expert\"', 'MERGE (_skill30:Skill{id:\\'_mongodb\\'}) ON CREATE SET _skill30.name = \"MongoDB\",_skill30.level = \"expert\"', 'MERGE (_skill31:Skill{id:\\'_mysql\\'}) ON CREATE SET _skill31.name = \"MySQL\",_skill31.level = \"expert\"', 'MERGE (_skill32:Skill{id:\\'_scrum\\'}) ON CREATE SET _skill32.name = \"SCRUM\",_skill32.level = \"expert\"', 'MERGE (_skill33:Skill{id:\\'_agile\\'}) ON CREATE SET _skill33.name = \"AGILE\",_skill33.level = \"expert\"', 'MERGE (_skill34:Skill{id:\\'_waterfall\\'}) ON CREATE SET _skill34.name = \"WATERFALL\",_skill34.level = \"expert\"', 'MERGE (_skill35:Skill{id:\\'_html5\\'}) ON CREATE SET _skill35.name = \"HTML5\",_skill35.level = \"expert\"', 'MERGE (_skill36:Skill{id:\\'_css3\\'}) ON CREATE SET _skill36.name = \"CSS3\",_skill36.level = \"expert\"', 'MERGE (_skill37:Skill{id:\\'_xml\\'}) ON CREATE SET _skill37.name = \"XML\",_skill37.level = \"expert\"', 'MERGE (_skill38:Skill{id:\\'_json\\'}) ON CREATE SET _skill38.name = \"JSON\",_skill38.level = \"expert\"', 'MERGE (_skill39:Skill{id:\\'_javascript\\'}) ON CREATE SET _skill39.name = \"JavaScript\",_skill39.level = \"expert\"', 'MERGE (_skill40:Skill{id:\\'_nodejs\\'}) ON CREATE SET _skill40.name = \"node.js\",_skill40.level = \"expert\"', 'MERGE (_skill41:Skill{id:\\'_npm\\'}) ON CREATE SET _skill41.name = \"NPM\",_skill41.level = \"expert\"', 'MERGE (_skill42:Skill{id:\\'_git\\'}) ON CREATE SET _skill42.name = \"GIT\",_skill42.level = \"expert\"', 'MERGE (_skill43:Skill{id:\\'_expressjs\\'}) ON CREATE SET _skill43.name = \"express.js\",_skill43.level = \"expert\"', 'MERGE (_skill44:Skill{id:\\'_jquery\\'}) ON CREATE SET _skill44.name = \"jQuery\",_skill44.level = \"expert\"', 'MERGE (_skill45:Skill{id:\\'_angular\\'}) ON CREATE SET _skill45.name = \"Angular\",_skill45.level = \"expert\"', 'MERGE (_skill46:Skill{id:\\'_bootstrap\\'}) ON CREATE SET _skill46.name = \"Bootstrap\",_skill46.level = \"expert\"', 'MERGE (_skill47:Skill{id:\\'_restfulapi\\'}) ON CREATE SET _skill47.name = \"Restful API\",_skill47.level = \"expert\"', 'MERGE (_skill48:Skill{id:\\'_java\\'}) ON CREATE SET _skill48.name = \"JAVA\",_skill48.level = \"expert\"', 'MERGE (_skill49:Skill{id:\\'_j2ee\\'}) ON CREATE SET _skill49.name = \"J2EE\",_skill49.level = \"expert\"', 'MERGE (_skill50:Skill{id:\\'_php\\'}) ON CREATE SET _skill50.name = \"PHP\",_skill50.level = \"expert\"', 'MERGE (_skill51:Skill{id:\\'_windows\\'}) ON CREATE SET _skill51.name = \"Windows\",_skill51.level = \"expert\"', 'MERGE (_skill52:Skill{id:\\'_macos\\'}) ON CREATE SET _skill52.name = \"Mac OS\",_skill52.level = \"expert\"', 'MERGE (_education1:Education{id:\\'e1686819653115374522\\'}) ON CREATE SET _education1.degree = \"Bachelor of Arts\",_education1.university = \"THE UNIVERSITY OF THAI CHAMBER OF COMMERCE - BANGKOK, TH\",_education1.graduationDate = \"May 2001\",_education1.score = \"0.0\"', 'MERGE (_education2:Education{id:\\'e1686819653115390239\\'}) ON CREATE SET _education2.degree = \"Master of Business Administration\",_education2.university = \"AMERICAN INTER CONTINENTAL UNIVERSITY ATLANTA\",_education2.graduationDate = \"December 2005\",_education2.score = \"0.0\"', 'MERGE (_education3:Education{id:\\'e1686819653115404282\\'}) ON CREATE SET _education3.degree = \"Master of Science in Information Technology\",_education3.university = \"KENNESAW STATE UNIVERSITY - Kennesaw, GA\",_education3.graduationDate = \"May 2015\",_education3.score = \"0.0\"'] [\"\\n      MATCH (_position1:Position{id:'j1686819653114612239'})\\n      MATCH (_company1:Company{id:'_tataconsultantcyser'})\\n      MERGE (_position1)-[:AT_COMPANY]->(_company1)\\n    \"]\n"
          ]
        }
      ],
      "source": [
        "ent_cyp, rel_cyp = generate_cypher([results])\n",
        "\n",
        "print(ent_cyp, rel_cyp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54c69170",
      "metadata": {
        "id": "54c69170",
        "tags": []
      },
      "source": [
        "## Data Ingestion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00f06013-a653-43cf-be7c-de2888e621f7",
      "metadata": {
        "id": "00f06013-a653-43cf-be7c-de2888e621f7"
      },
      "source": [
        "You will need a Neo4j AuraDS Pro instance.  You can deploy that on Google Cloud Marketplace [here](https://console.cloud.google.com/marketplace/product/endpoints/prod.n4gcp.neo4j.io).\n",
        "\n",
        "With that complete, you'll need to install the Neo4j library and set up your database connection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e621c199-533a-4503-baef-200c5adcd8ad",
      "metadata": {
        "id": "e621c199-533a-4503-baef-200c5adcd8ad"
      },
      "outputs": [],
      "source": [
        "from neo4j import GraphDatabase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ecea5ff",
      "metadata": {
        "id": "0ecea5ff"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "\n",
        "# You will need to change these variables\n",
        "connectionUrl = \"bolt://3.238.140.38:7687\"\n",
        "username = \"neo4j\"\n",
        "password = \"streams-waist-splashes\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddbfa6e8",
      "metadata": {
        "id": "ddbfa6e8"
      },
      "outputs": [],
      "source": [
        "driver = GraphDatabase.driver(connectionUrl, auth=(username, password))\n",
        "driver.verify_connectivity()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44d1b7ed-539d-4d41-a2b8-0969bcc41395",
      "metadata": {
        "id": "44d1b7ed-539d-4d41-a2b8-0969bcc41395"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def run_query(query, params={}):\n",
        "    with driver.session() as session:\n",
        "        result = session.run(query, params)\n",
        "        return pd.DataFrame([r.values() for r in result], columns=result.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228a3a58",
      "metadata": {
        "id": "228a3a58"
      },
      "source": [
        "Before loading the data, create constraints as below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66756bab",
      "metadata": {
        "id": "66756bab",
        "outputId": "9d74f22e-e5e0-4fbb-eab9-c7981898b9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d314999-74ee-478b-ad8e-fe3c260ea063\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d314999-74ee-478b-ad8e-fe3c260ea063')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d314999-74ee-478b-ad8e-fe3c260ea063 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d314999-74ee-478b-ad8e-fe3c260ea063');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "run_query('CREATE CONSTRAINT unique_person_id IF NOT EXISTS FOR (n:Person) REQUIRE (n.id) IS UNIQUE')\n",
        "run_query('CREATE CONSTRAINT unique_position_id IF NOT EXISTS FOR (n:Position) REQUIRE (n.id) IS UNIQUE')\n",
        "run_query('CREATE CONSTRAINT unique_skill_id IF NOT EXISTS FOR (n:Skill) REQUIRE n.id IS UNIQUE')\n",
        "run_query('CREATE CONSTRAINT unique_education_id IF NOT EXISTS FOR (n:Education) REQUIRE n.id IS UNIQUE')\n",
        "run_query('CREATE CONSTRAINT unique_company_id IF NOT EXISTS FOR (n:Company) REQUIRE n.id IS UNIQUE')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "971bf0b3",
      "metadata": {
        "id": "971bf0b3"
      },
      "source": [
        "Ingest the entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7367ece7",
      "metadata": {
        "id": "7367ece7",
        "outputId": "1489b01d-22a1-4d00-b2b7-39493d5dbab6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 288 ms, sys: 15.6 ms, total: 303 ms\n",
            "Wall time: 26.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for e in ent_cyp:\n",
        "    run_query(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f811933",
      "metadata": {
        "id": "0f811933"
      },
      "source": [
        "Ingest relationships now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ff4ad1",
      "metadata": {
        "id": "d9ff4ad1",
        "outputId": "f4bf4e39-4e4a-4c11-c6d8-729e967d3d69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.85 s, sys: 101 ms, total: 1.96 s\n",
            "Wall time: 1min 40s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for r in rel_cyp:\n",
        "    run_query(r)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "bfnoXjseXv1M",
        "outputId": "fbc7905c-62d3-4835-c291-de1d2db433e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bfnoXjseXv1M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d0f5076-188c-49d4-9df9-914540d45618",
      "metadata": {
        "id": "1d0f5076-188c-49d4-9df9-914540d45618"
      },
      "source": [
        "Your ingested data from the above commands might look like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46273cf0-fe01-442f-a4ad-1f9fb4e274b4",
      "metadata": {
        "id": "46273cf0-fe01-442f-a4ad-1f9fb4e274b4"
      },
      "source": [
        "![ingested_data.png](attachment:4d918a28-09df-46ef-92a5-29fe0462f490.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c65581a1",
      "metadata": {
        "id": "c65581a1"
      },
      "source": [
        "We got thousands of Resumes in the `data` directory. Let us run a pipeline to ingest only a few of them now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b707904c",
      "metadata": {
        "id": "b707904c"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "def run_pipeline(start=0, count=1):\n",
        "    txt_files = glob.glob(\"/content/intelligent-app-google-generativeai-neo4j/notebook/data/*.txt\")[start:count]\n",
        "    print(f\"Running pipeline for {len(txt_files)} files\")\n",
        "    failed_files = process_pipeline(txt_files)\n",
        "    print(failed_files)\n",
        "    return failed_files\n",
        "\n",
        "def process_pipeline(files):\n",
        "    failed_files = []\n",
        "    i = 0\n",
        "    for f in files:\n",
        "        i += 1\n",
        "        try:\n",
        "            with open(f, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "                print(f\"  {f}: Reading File No. ({i})\")\n",
        "                data = file.read().rstrip()\n",
        "                text = data\n",
        "                print(f\"    {f}: Extracting Entities & Relationships\")\n",
        "                results = run_extraction(f, text)\n",
        "                print(f\"    {f}: Generating Cypher\")\n",
        "                ent_cyp, rel_cyp = generate_cypher(results)\n",
        "                print(f\"    {f}: Ingesting Entities\")\n",
        "                for e in ent_cyp:\n",
        "                    run_query(e)\n",
        "                print(f\"    {f}: Ingesting Relationships\")\n",
        "                for r in rel_cyp:\n",
        "                    run_query(r)\n",
        "                print(f\"    {f}: Processing DONE\")\n",
        "        except Exception as e:\n",
        "            print(f\"    {f}: Processing Failed with exception {e}\")\n",
        "            failed_files.append(f)\n",
        "    return failed_files\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "def run_extraction(f, text):\n",
        "    start = timer()\n",
        "    prompts = [person_prompt_tpl, postion_prompt_tpl, skill_prompt_tpl, edu_prompt_tpl]\n",
        "    results = {\"entities\": [], \"relationships\": []}\n",
        "    for p in prompts:\n",
        "        _prompt = Template(p).substitute(ctext=text)\n",
        "        _extraction = extract_entities_relationships(_prompt, '')\n",
        "        if 'Answer:\\n' in _extraction:\n",
        "            _extraction = _extraction.split('Answer:\\n ')[1]\n",
        "        if _extraction.strip() == '':\n",
        "            continue\n",
        "        try:\n",
        "            _extraction = json.loads(_extraction.replace(\"\\'\", \"'\"))\n",
        "        except json.JSONDecodeError:\n",
        "            #Temp hack to ignore Skills cut off by token limitation\n",
        "            _extraction = _extraction[:_extraction.rfind(\"}\")+1] + ']}'\n",
        "            _extraction = json.loads(_extraction.replace(\"\\'\", \"'\"))\n",
        "        results[\"entities\"].extend(_extraction[\"entities\"])\n",
        "        if \"relationships\" in _extraction:\n",
        "            results[\"relationships\"].extend(_extraction[\"relationships\"])\n",
        "    person_id = results[\"entities\"][0][\"id\"]\n",
        "    for e in results[\"entities\"][1:]:\n",
        "        if e['label'] == 'Position':\n",
        "            results[\"relationships\"].append(f\"{person_id}|HAS_POSITION|{e['id']}\")\n",
        "        if e['label'] == 'Skill':\n",
        "            results[\"relationships\"].append(f\"{person_id}|HAS_SKILL|{e['id']}\")\n",
        "        if e['label'] == 'Education':\n",
        "            results[\"relationships\"].append(f\"{person_id}|HAS_EDUCATION|{e['id']}\")\n",
        "    end = timer()\n",
        "    elapsed = (end-start)\n",
        "    print(f\"    {f}: Entity Extraction took {elapsed}secs\")\n",
        "    return [results]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe2feb86-2938-4842-9e7b-f2ba45bada1c",
      "metadata": {
        "id": "fe2feb86-2938-4842-9e7b-f2ba45bada1c"
      },
      "source": [
        "Lets run the pipeline only for the first 100 files. This will only process those 10 files and ingested them to Neo4j. It usually takes around 30-45 minutes for 100 files.\n",
        "\n",
        "In your case, you may need to run the pipeline for 1000s of files inside the `data` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb4b86a7",
      "metadata": {
        "id": "bb4b86a7"
      },
      "outputs": [],
      "source": [
        "%%capture ingestion_output\n",
        "%%time\n",
        "failed_files = run_pipeline(0, 100) # runs ingestion pipeline for files from index 0 to 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9367ffca-53ad-42d7-9ff7-35314759a425",
      "metadata": {
        "id": "9367ffca-53ad-42d7-9ff7-35314759a425",
        "outputId": "61cfe825-f15f-4b7f-bc5b-9a58f215de11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running pipeline for 100 files\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09609.txt: Reading File No. (1)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09609.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09609.txt: Entity Extraction took 7.788660138000068secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09609.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09609.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09609.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09609.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08519.txt: Reading File No. (2)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08519.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08519.txt: Entity Extraction took 15.211925076999705secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08519.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08519.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08519.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08519.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/10365.txt: Reading File No. (3)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10365.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10365.txt: Entity Extraction took 9.017241965999801secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10365.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10365.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10365.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10365.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08412.txt: Reading File No. (4)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08412.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08412.txt: Entity Extraction took 13.535773725000126secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08412.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08412.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08412.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08412.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07384.txt: Reading File No. (5)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07384.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07384.txt: Entity Extraction took 12.591920353000205secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07384.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07384.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07384.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07384.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07653.txt: Reading File No. (6)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07653.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07653.txt: Entity Extraction took 14.988967610000145secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07653.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07653.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07653.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07653.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/05726.txt: Reading File No. (7)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05726.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05726.txt: Entity Extraction took 12.173896893999881secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05726.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05726.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05726.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05726.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09502.txt: Reading File No. (8)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09502.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09502.txt: Entity Extraction took 14.295730724999885secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09502.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09502.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09502.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09502.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/05650.txt: Reading File No. (9)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05650.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05650.txt: Entity Extraction took 8.690499043000273secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05650.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05650.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05650.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05650.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/10357.txt: Reading File No. (10)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10357.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10357.txt: Entity Extraction took 11.185517029000039secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10357.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10357.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10357.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10357.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06588.txt: Reading File No. (11)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06588.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06588.txt: Entity Extraction took 8.49272331100019secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06588.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06588.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06588.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06588.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07162.txt: Reading File No. (12)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07162.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07162.txt: Processing Failed with exception Invalid \\escape: line 1 column 79 (char 78)\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08455.txt: Reading File No. (13)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08455.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08455.txt: Entity Extraction took 10.99218860100018secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08455.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08455.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08455.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08455.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08472.txt: Reading File No. (14)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08472.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08472.txt: Entity Extraction took 9.712155981999786secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08472.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08472.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08472.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08472.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08018.txt: Reading File No. (15)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08018.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08018.txt: Entity Extraction took 19.108170826000332secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08018.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08018.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08018.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08018.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/05594.txt: Reading File No. (16)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05594.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05594.txt: Entity Extraction took 8.972344035000333secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05594.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05594.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05594.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05594.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07101.txt: Reading File No. (17)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07101.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07101.txt: Entity Extraction took 17.482645884999783secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07101.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07101.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07101.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07101.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09777.txt: Reading File No. (18)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09777.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09777.txt: Entity Extraction took 10.969159766000303secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09777.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09777.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09777.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09777.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09163.txt: Reading File No. (19)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09163.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09163.txt: Entity Extraction took 20.39165797600026secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09163.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09163.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09163.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09163.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/05983.txt: Reading File No. (20)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05983.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05983.txt: Entity Extraction took 7.167281066000214secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05983.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05983.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05983.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05983.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07592.txt: Reading File No. (21)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07592.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07592.txt: Entity Extraction took 7.145554363999963secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07592.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07592.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07592.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07592.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08737.txt: Reading File No. (22)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08737.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08737.txt: Entity Extraction took 13.652690352999798secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08737.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08737.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08737.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08737.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08733.txt: Reading File No. (23)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08733.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08733.txt: Entity Extraction took 6.439124115999675secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08733.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08733.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08733.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08733.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06851.txt: Reading File No. (24)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06851.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06851.txt: Entity Extraction took 7.066809796000143secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06851.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06851.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06851.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06851.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07476.txt: Reading File No. (25)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07476.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07476.txt: Entity Extraction took 19.828264493000006secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07476.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07476.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07476.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07476.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06991.txt: Reading File No. (26)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06991.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06991.txt: Entity Extraction took 17.184831029999714secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06991.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06991.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06991.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06991.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09601.txt: Reading File No. (27)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09601.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09601.txt: Entity Extraction took 22.775692361999972secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09601.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09601.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09601.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09601.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09220.txt: Reading File No. (28)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09220.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09220.txt: Processing Failed with exception Expecting value: line 1 column 1 (char 0)\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/10184.txt: Reading File No. (29)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10184.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10184.txt: Entity Extraction took 17.005479538000145secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10184.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10184.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10184.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10184.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06847.txt: Reading File No. (30)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06847.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06847.txt: Entity Extraction took 12.39792129200032secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06847.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06847.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06847.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06847.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07352.txt: Reading File No. (31)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07352.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07352.txt: Entity Extraction took 14.688323906999813secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07352.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07352.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07352.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07352.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/10222.txt: Reading File No. (32)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10222.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10222.txt: Entity Extraction took 11.460299322000083secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10222.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10222.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10222.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10222.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07033.txt: Reading File No. (33)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07033.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07033.txt: Entity Extraction took 16.143976508999913secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07033.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07033.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07033.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07033.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/05548.txt: Reading File No. (34)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05548.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05548.txt: Entity Extraction took 19.475683611000022secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05548.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05548.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05548.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05548.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07792.txt: Reading File No. (35)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07792.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07792.txt: Entity Extraction took 8.347148453000045secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07792.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07792.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07792.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07792.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/10427.txt: Reading File No. (36)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10427.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10427.txt: Entity Extraction took 14.674803733000317secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10427.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10427.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10427.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10427.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09476.txt: Reading File No. (37)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09476.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09476.txt: Entity Extraction took 16.72300689900021secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09476.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09476.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09476.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09476.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06371.txt: Reading File No. (38)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06371.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06371.txt: Entity Extraction took 9.311533612999938secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06371.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06371.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06371.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06371.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/05560.txt: Reading File No. (39)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05560.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05560.txt: Entity Extraction took 10.634307829000136secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05560.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05560.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05560.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05560.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09866.txt: Reading File No. (40)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09866.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09866.txt: Entity Extraction took 9.164902443999836secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09866.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09866.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09866.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09866.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/10211.txt: Reading File No. (41)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10211.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10211.txt: Entity Extraction took 13.63176920099977secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10211.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10211.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10211.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10211.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09157.txt: Reading File No. (42)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09157.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09157.txt: Entity Extraction took 15.172916367999733secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09157.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09157.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09157.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09157.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07116.txt: Reading File No. (43)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07116.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07116.txt: Entity Extraction took 13.766217890000007secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07116.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07116.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07116.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07116.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/05980.txt: Reading File No. (44)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05980.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05980.txt: Entity Extraction took 10.821189653000147secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05980.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05980.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05980.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05980.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08175.txt: Reading File No. (45)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08175.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08175.txt: Entity Extraction took 16.170716788999925secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08175.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08175.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08175.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08175.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06434.txt: Reading File No. (46)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06434.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06434.txt: Entity Extraction took 11.223065809000218secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06434.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06434.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06434.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06434.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09258.txt: Reading File No. (47)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09258.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09258.txt: Entity Extraction took 10.762973449999663secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09258.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09258.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09258.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09258.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/10317.txt: Reading File No. (48)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10317.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10317.txt: Entity Extraction took 10.790943419000541secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10317.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10317.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10317.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10317.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/10341.txt: Reading File No. (49)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10341.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10341.txt: Entity Extraction took 14.395156642000074secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10341.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10341.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10341.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10341.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09894.txt: Reading File No. (50)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09894.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09894.txt: Entity Extraction took 17.169649504999143secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09894.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09894.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09894.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09894.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07412.txt: Reading File No. (51)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07412.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07412.txt: Entity Extraction took 12.908420461999413secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07412.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07412.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07412.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07412.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07364.txt: Reading File No. (52)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07364.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07364.txt: Entity Extraction took 13.239540200999727secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07364.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07364.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07364.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07364.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08743.txt: Reading File No. (53)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08743.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08743.txt: Entity Extraction took 12.891422231999968secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08743.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08743.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08743.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08743.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07619.txt: Reading File No. (54)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07619.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07619.txt: Entity Extraction took 13.257523062000473secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07619.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07619.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07619.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07619.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06396.txt: Reading File No. (55)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06396.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06396.txt: Entity Extraction took 19.53794322399972secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06396.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06396.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06396.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06396.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08886.txt: Reading File No. (56)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08886.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08886.txt: Entity Extraction took 12.006051053000192secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08886.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08886.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08886.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08886.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09652.txt: Reading File No. (57)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09652.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09652.txt: Entity Extraction took 13.391862008000317secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09652.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09652.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09652.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09652.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07729.txt: Reading File No. (58)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07729.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07729.txt: Entity Extraction took 16.384438933000638secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07729.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07729.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07729.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07729.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06962.txt: Reading File No. (59)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06962.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06962.txt: Entity Extraction took 6.579667406000226secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06962.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06962.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06962.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06962.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/10068.txt: Reading File No. (60)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10068.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10068.txt: Entity Extraction took 14.468274528999245secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10068.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10068.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10068.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10068.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09278.txt: Reading File No. (61)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09278.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09278.txt: Entity Extraction took 12.175358168999992secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09278.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09278.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09278.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09278.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07941.txt: Reading File No. (62)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07941.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07941.txt: Entity Extraction took 14.639193651999449secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07941.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07941.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07941.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07941.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09075.txt: Reading File No. (63)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09075.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09075.txt: Entity Extraction took 8.408620365999923secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09075.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09075.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09075.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09075.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09939.txt: Reading File No. (64)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09939.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09939.txt: Entity Extraction took 11.720490995000546secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09939.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09939.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09939.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09939.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07168.txt: Reading File No. (65)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07168.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07168.txt: Entity Extraction took 15.401832102999833secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07168.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07168.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07168.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07168.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06556.txt: Reading File No. (66)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06556.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06556.txt: Entity Extraction took 10.558592676999979secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06556.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06556.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06556.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06556.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07551.txt: Reading File No. (67)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07551.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07551.txt: Entity Extraction took 19.696732923000127secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07551.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07551.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07551.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07551.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07026.txt: Reading File No. (68)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07026.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07026.txt: Entity Extraction took 15.456294137999976secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07026.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07026.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07026.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07026.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09830.txt: Reading File No. (69)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09830.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09830.txt: Processing Failed with exception Expecting value: line 1 column 1 (char 0)\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/10355.txt: Reading File No. (70)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10355.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10355.txt: Entity Extraction took 13.190010303000236secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10355.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10355.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10355.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10355.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06050.txt: Reading File No. (71)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06050.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06050.txt: Entity Extraction took 16.919128903000455secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06050.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06050.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06050.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06050.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06101.txt: Reading File No. (72)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06101.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06101.txt: Entity Extraction took 8.434650928999872secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06101.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06101.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06101.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06101.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07611.txt: Reading File No. (73)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07611.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07611.txt: Entity Extraction took 13.132690573999753secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07611.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07611.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07611.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07611.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06265.txt: Reading File No. (74)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06265.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06265.txt: Entity Extraction took 8.911728389000018secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06265.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06265.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06265.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06265.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08621.txt: Reading File No. (75)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08621.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08621.txt: Entity Extraction took 15.001435112999388secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08621.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08621.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08621.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08621.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/05870.txt: Reading File No. (76)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05870.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05870.txt: Entity Extraction took 8.979785553999136secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05870.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05870.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05870.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05870.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/05736.txt: Reading File No. (77)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05736.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05736.txt: Entity Extraction took 18.965574767000362secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05736.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05736.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05736.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/05736.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06719.txt: Reading File No. (78)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06719.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06719.txt: Entity Extraction took 15.017084502000216secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06719.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06719.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06719.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06719.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07754.txt: Reading File No. (79)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07754.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07754.txt: Entity Extraction took 14.487907419999829secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07754.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07754.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07754.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07754.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09986.txt: Reading File No. (80)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09986.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09986.txt: Entity Extraction took 17.146427583999866secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09986.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09986.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09986.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09986.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06329.txt: Reading File No. (81)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06329.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06329.txt: Entity Extraction took 13.32886882999992secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06329.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06329.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06329.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06329.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09357.txt: Reading File No. (82)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09357.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09357.txt: Entity Extraction took 18.164543555999444secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09357.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09357.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09357.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09357.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07104.txt: Reading File No. (83)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07104.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07104.txt: Entity Extraction took 16.692386744000032secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07104.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07104.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07104.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07104.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08982.txt: Reading File No. (84)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08982.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08982.txt: Entity Extraction took 14.853486238999722secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08982.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08982.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08982.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08982.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09692.txt: Reading File No. (85)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09692.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09692.txt: Entity Extraction took 12.970737929000279secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09692.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09692.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09692.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09692.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/10185.txt: Reading File No. (86)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10185.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10185.txt: Entity Extraction took 14.50762351999947secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10185.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10185.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10185.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10185.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07368.txt: Reading File No. (87)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07368.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07368.txt: Entity Extraction took 15.929625284000394secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07368.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07368.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07368.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07368.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06405.txt: Reading File No. (88)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06405.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06405.txt: Entity Extraction took 8.928739900999972secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06405.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06405.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06405.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06405.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08842.txt: Reading File No. (89)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08842.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08842.txt: Entity Extraction took 9.401104026999747secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08842.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08842.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08842.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08842.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09820.txt: Reading File No. (90)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09820.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09820.txt: Entity Extraction took 8.6830085470001secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09820.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09820.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09820.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09820.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07512.txt: Reading File No. (91)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07512.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07512.txt: Entity Extraction took 15.941484365000179secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07512.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07512.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07512.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07512.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07001.txt: Reading File No. (92)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07001.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07001.txt: Entity Extraction took 23.42809103000036secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07001.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07001.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07001.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07001.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06547.txt: Reading File No. (93)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06547.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06547.txt: Entity Extraction took 13.813369411999702secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06547.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06547.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06547.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06547.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/08928.txt: Reading File No. (94)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08928.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08928.txt: Entity Extraction took 8.945253337000395secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08928.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08928.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08928.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/08928.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07771.txt: Reading File No. (95)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07771.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07771.txt: Entity Extraction took 25.820466703999955secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07771.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07771.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07771.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07771.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/10116.txt: Reading File No. (96)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10116.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10116.txt: Entity Extraction took 14.951366168999812secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10116.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10116.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10116.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/10116.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/09453.txt: Reading File No. (97)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09453.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09453.txt: Entity Extraction took 17.516859808000845secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09453.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09453.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09453.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/09453.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06771.txt: Reading File No. (98)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06771.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06771.txt: Entity Extraction took 18.679144544999872secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06771.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06771.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06771.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06771.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/06606.txt: Reading File No. (99)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06606.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06606.txt: Entity Extraction took 8.029720802999691secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06606.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06606.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06606.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/06606.txt: Processing DONE\n",
            "  /content/intelligent-app-google-generativeai-neo4j/notebook/data/07209.txt: Reading File No. (100)\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07209.txt: Extracting Entities & Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07209.txt: Entity Extraction took 13.29476429999977secs\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07209.txt: Generating Cypher\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07209.txt: Ingesting Entities\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07209.txt: Ingesting Relationships\n",
            "    /content/intelligent-app-google-generativeai-neo4j/notebook/data/07209.txt: Processing DONE\n",
            "['/content/intelligent-app-google-generativeai-neo4j/notebook/data/07162.txt', '/content/intelligent-app-google-generativeai-neo4j/notebook/data/09220.txt', '/content/intelligent-app-google-generativeai-neo4j/notebook/data/09830.txt']\n",
            "CPU times: user 35.4 s, sys: 3.38 s, total: 38.8 s\n",
            "Wall time: 35min 50s\n"
          ]
        }
      ],
      "source": [
        "ingestion_output.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "653e9c48",
      "metadata": {
        "id": "653e9c48"
      },
      "source": [
        "If processing failed for some files due to API Rate limit, you can retry as below. For token limitation error, it is better to chunk the text and retry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e26a851",
      "metadata": {
        "id": "4e26a851"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "failed_files = process_pipeline(failed_files)\n",
        "failed_files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UrvbzyY_X8uP",
      "metadata": {
        "id": "UrvbzyY_X8uP",
        "tags": []
      },
      "source": [
        "## Cypher Generation for Consumption"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c06e57d-72a9-4b86-8b8d-119690895c02",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "7c06e57d-72a9-4b86-8b8d-119690895c02"
      },
      "source": [
        "### Tune the model to generate Cypher (OPTIONAL)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe379dfb-023f-4664-82e8-7fc8e016ba5d",
      "metadata": {
        "id": "fe379dfb-023f-4664-82e8-7fc8e016ba5d"
      },
      "source": [
        "The Codey family of models perform well for Cypher generation with few-shot prompting. However, they are not tunable at the moment. If you need to tune a model for specific Cypher Generation task, you can consider `text-bison` model we used during the ingestion process above. So, the tuning section below is completely optional.\n",
        "\n",
        "\n",
        "The `text-bison` base model can be tuned to generate more accurate Cypher. Lets see how to adapter tune it. We will try to tune the model with some Cypher statements. The model achieves some Cypher generation capability but could be better. It is suggested to try with at least a few hundred statements. You should aim for more quality training data.\n",
        "\n",
        "The total training time below takes more than an hour. The tuned adapter model is going to stay within your tenant and your training data will not be used to train the base model which is frozen. Tuning runs on GCP's TPU infrastructure that is optimised to run ML workloads."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f785e716-2ba1-4d9f-b949-296c9285a1bc",
      "metadata": {
        "id": "f785e716-2ba1-4d9f-b949-296c9285a1bc"
      },
      "source": [
        "First, let us upload our training set in `jsonl` format to a GCS bucket. We will use this file `finetuning/eng-to-cypher-trng.jsonl` for our fine-tuning. You can take a look over the data there.\n",
        "\n",
        "VertexAI expects you to adhere to this format for each line of the `jsonl` file.\n",
        "```json\n",
        "{\"input_text\": \"MY_INPUT_PROMPT\", \"output_text\": \"CYPHER_QUERY\"}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a2ede9-643b-4adc-a30f-0f26fb61fd47",
      "metadata": {
        "id": "b9a2ede9-643b-4adc-a30f-0f26fb61fd47"
      },
      "source": [
        "When you got some changes in the training data, ensure that you upload the updated file in a different name than your previous tuning exercises. Because Vertex AI caches data uploaded previously, it skips any file validation and uses the previously uploaded data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6316e464-5dbf-475d-8507-de07ba0bc0c0",
      "metadata": {
        "id": "6316e464-5dbf-475d-8507-de07ba0bc0c0"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "bucket_name = project_id + '-genai'\n",
        "client = storage.Client()\n",
        "try:\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "except:\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    bucket.storage_class = 'STANDARD'\n",
        "    bucket = client.create_bucket(bucket)\n",
        "\n",
        "upload_name = f\"finetuning/eng-to-cypher-trng-{timer()}.jsonl\" #this ensures vertexai reloads the file\n",
        "filename = 'finetuning/eng-to-cypher-trng.jsonl'\n",
        "blob = bucket.blob(upload_name)\n",
        "blob.upload_from_filename(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76f8cd32-e509-4ec1-bd74-ba6ee9142c3f",
      "metadata": {
        "id": "76f8cd32-e509-4ec1-bd74-ba6ee9142c3f"
      },
      "source": [
        "Let's tune the model for a hundred training steps. When you the below code, the following sequence happens:\n",
        "1. Pipeline Validation\n",
        "2. Dataset Export\n",
        "3. Prompt Validation\n",
        "4. jsonl to tfrecord conversion\n",
        "5. Parameter Composition for Adapter tuning\n",
        "6. LLM Tuning\n",
        "7. Model uploading and\n",
        "8. Endpoint deployment\n",
        "\n",
        "![finetune-seq.png](attachment:2779e9d0-845d-4aea-a38d-4e5f681ba36d.png)\n",
        "\n",
        "This tuning takes approximately 2 hours to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52790af0-83c8-4373-8716-91fcea4b87a7",
      "metadata": {
        "id": "52790af0-83c8-4373-8716-91fcea4b87a7"
      },
      "outputs": [],
      "source": [
        "training_data = 'gs://' + bucket_name + '/' + upload_name\n",
        "train_steps = 100\n",
        "\n",
        "vertexai.init(project=project_id, location=location)\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "\n",
        "model.tune_model(\n",
        "  training_data=training_data,\n",
        "  train_steps=train_steps,\n",
        "  tuning_job_location=\"europe-west4\",\n",
        "  tuned_model_location=\"us-central1\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b313858-08be-4e62-bd49-c120afac0b44",
      "metadata": {
        "id": "4b313858-08be-4e62-bd49-c120afac0b44"
      },
      "source": [
        "To get the details of the adapter tuned model, run this command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92112808-bb7c-460f-b06e-a9c319bbc8fa",
      "metadata": {
        "id": "92112808-bb7c-460f-b06e-a9c319bbc8fa",
        "outputId": "7455e8a7-7783-4a80-987b-bdbcb4931969"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'projects/803648085855/locations/us-central1/models/5274253924348461056'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "models = model.list_tuned_model_names()\n",
        "\n",
        "# The first model in the list is the one we just tuned.\n",
        "entity_extraction_tuned_model = models[0]\n",
        "entity_extraction_tuned_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e9f2895-c3c4-401c-a4d6-cf1b80a2050b",
      "metadata": {
        "id": "5e9f2895-c3c4-401c-a4d6-cf1b80a2050b"
      },
      "outputs": [],
      "source": [
        "def english_to_cypher_text_bison(prompt, tuned_model_name = ''):\n",
        "    try:\n",
        "        res = run_text_model(project_id, \"text-bison@001\", 0.1, 1024, 0.95, 40, prompt, location, tuned_model_name)\n",
        "        return res\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a113928b-b83d-4f41-833b-a92e851cca3a",
      "metadata": {
        "tags": [],
        "id": "a113928b-b83d-4f41-833b-a92e851cca3a"
      },
      "source": [
        "### Generate Cypher\n",
        "If you are not tuning the `text-bison` model for Cypher generation, you can consider the `code-bison` model from the Codey Models family. Let us see how to use it for Cypher generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f1148c7-b0ac-44ed-a8af-d557c10fbcd6",
      "metadata": {
        "id": "5f1148c7-b0ac-44ed-a8af-d557c10fbcd6"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform.gapic.schema import predict\n",
        "from google.protobuf import json_format\n",
        "from google.protobuf.struct_pb2 import Value\n",
        "\n",
        "def generate_code(\n",
        "    api_endpoint: str,\n",
        "    endpoint: str,\n",
        "    input: str,\n",
        "    parameters: str,\n",
        "    location: str = \"us-central1\",\n",
        "):\n",
        "  # The AI Platform services require regional API endpoints.\n",
        "  client_options = {\"api_endpoint\": api_endpoint}\n",
        "  # Initialize client that will be used to create and send requests.\n",
        "  # This client only needs to be created once, and can be reused for multiple requests.\n",
        "  client = aiplatform.gapic.PredictionServiceClient(\n",
        "      client_options=client_options\n",
        "  )\n",
        "  instance_dict = input\n",
        "  instance = json_format.ParseDict(instance_dict, Value())\n",
        "  instances = [instance]\n",
        "  parameters_dict = parameters\n",
        "  parameters = json_format.ParseDict(parameters_dict, Value())\n",
        "  response = client.predict(\n",
        "      endpoint=endpoint, instances=instances, parameters=parameters\n",
        "  )\n",
        "  predictions = response.predictions\n",
        "  return predictions[0][\"content\"]\n",
        "\n",
        "def english_to_cypher_code_bison(prompt):\n",
        "    try:\n",
        "        res = generate_code(\"us-central1-aiplatform.googleapis.com\", \"projects/workshop-trvlk/locations/us-central1/publishers/google/models/code-bison@001\", {\n",
        "                  \"prefix\": prompt\n",
        "                }, {\"temperature\": 0, \"maxOutputTokens\": 2048}, \"us-central1\")\n",
        "        return res\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1d2f78f-74f7-4ef2-bb65-ed9c83d69f95",
      "metadata": {
        "id": "f1d2f78f-74f7-4ef2-bb65-ed9c83d69f95"
      },
      "source": [
        "We have to create a prompt template that clearly states what schema to use, what kind of Cypher to generate and how."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55cfc38e-695d-4f51-8028-f44d24597158",
      "metadata": {
        "id": "55cfc38e-695d-4f51-8028-f44d24597158"
      },
      "outputs": [],
      "source": [
        "samples = \"\"\"\n",
        "Question: How many expert java developers attend more than one universities?\n",
        "Answer: MATCH (p:Person)-[:HAS_SKILL]->(s:Skill), (p)-[:HAS_EDUCATION]->(e1:Education), (p)-[:HAS_EDUCATION]->(e2:Education) WHERE toLower(s.name) CONTAINS 'java' AND toLower(s.level) CONTAINS 'expert' AND e1.university <> e2.university RETURN COUNT(DISTINCT p)\n",
        "\n",
        "Question: Where do most candidates get educated?\n",
        "Answer: MATCH (p:Person)-[:HAS_EDUCATION]->(e:Education) RETURN e.university, count(e.university) as alumni ORDER BY alumni DESC LIMIT 1\n",
        "\n",
        "Question: How many people have worked as a Data Scientist in San Francisco?\n",
        "Answer: MATCH (p:Person)-[:HAS_POSITION]->(pos:Position) WHERE toLower(pos.title) CONTAINS 'data scientist' AND toLower(pos.location) CONTAINS 'san francisco' RETURN COUNT(p)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13794151-c535-4603-b825-b7d6adb51a12",
      "metadata": {
        "id": "13794151-c535-4603-b825-b7d6adb51a12"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"You are an expert Neo4j Cypher translator who understands the question in english and convert to Cypher strictly based on the Neo4j Schema provided and following the instructions below:\n",
        "1. Generate Cypher query compatible ONLY for Neo4j Version 5\n",
        "2. Do not use EXISTS, SIZE keywords in the cypher. Use alias when using the WITH keyword\n",
        "3. Use only Nodes and relationships mentioned in the schema\n",
        "4. Always enclose the Cypher output inside 3 backticks\n",
        "5. Always do a case-insensitive and fuzzy search for any properties related search. Eg: to search for a Company name use `toLower(c.name) contains 'neo4j'`\n",
        "6. Candidate node is synonymous to Person\n",
        "7. Always use aliases to refer the node in the query\n",
        "8. Cypher is NOT SQL. So, do not mix and match the syntaxes\n",
        "Schema:\n",
        "(:Person {label: 'Person', id: string, role: string, description: string})-[:HAS_POSITION {}]->(:Position {label: 'Position', id: string, title: string, location: string, startDate: string, endDate: string, url: string})\n",
        "(:Position {label: 'Position', id: string, title: string, location: string, startDate: string, endDate: string, url: string})-[:AT_COMPANY {}]->(:Company {label:'Company', id: string, name: string})\n",
        "(:Person {label: 'Person',id: string, role: string, description: string})-[:HAS_SKILL {}]->(:Skill {label:'Skill', id: string,name: string,level: string})\n",
        "(:Person {label: 'Person',id: string, role: string, description: string})-[:HAS_EDUCATION {}]->(:Education {label:'Education', id: string, degree: string, university: string, graduationDate: string, score: string, url: string})\n",
        "Samples:\n",
        "$samples\n",
        "Question: $question\n",
        "Answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EMZysiC9YsqC",
      "metadata": {
        "id": "EMZysiC9YsqC",
        "outputId": "806434a6-9dcf-440d-ec15-af3eb8d1b53a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'``` MATCH (p:Person)-[:HAS_SKILL]->(s:Skill) WHERE toLower(s.name) IN [\"java\", \"python\", \"javascript\", \"security\"] RETURN COUNT(DISTINCT p) ```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "from string import Template\n",
        "que = 'How many are knowledgable on all of - java, python, javascript, security?'\n",
        "_prompt = Template(prompt).substitute(samples=samples, question=que)\n",
        "\n",
        "cypher = english_to_cypher_code_bison(_prompt) #for text-bison use: english_to_cypher_text_bison(_prompt, entity_extraction_tuned_model)\n",
        "if 'Answer:\\n ' in cypher:\n",
        "    cypher = cypher.split('Answer:\\n ')[1]\n",
        "cypher = cypher.replace('\\n', ' ')\n",
        "cypher\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90ac31d0-ca59-47cc-81be-ebbd121d86d8",
      "metadata": {
        "tags": [],
        "id": "90ac31d0-ca59-47cc-81be-ebbd121d86d8"
      },
      "source": [
        "## Talent Finder Chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9212ac86-6c96-4640-a545-c9655e8d52d8",
      "metadata": {
        "id": "9212ac86-6c96-4640-a545-c9655e8d52d8"
      },
      "source": [
        "You can also create a chatbot that can help our interaction with Neo4j using English.\n",
        "\n",
        "Both Vertex AI and Neo4j support LangChain.  We will be using LangChain to quickly build a chatbot that converts English to Cypher and then executes it on Neo4j.  This is augmented using generative AI before sending the response to the user.  This makes graph consumption easier for non-cypher experts."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "364e1171-1c1f-4fff-8cf3-58426e76f030",
      "metadata": {
        "id": "364e1171-1c1f-4fff-8cf3-58426e76f030"
      },
      "source": [
        "The diagram below shows how Neo4j and Vertex AI will interact using LangChain.\n",
        "\n",
        "![langchain-neo4j.png](attachment:3c17193b-0097-47b6-bd7c-8f8659aa0e2f.png)\n",
        "\n",
        "First we have to create Neo4jGraph and VertexLLM Connection objects."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "323de133-3779-4466-aea4-3ab66c262002",
      "metadata": {
        "id": "323de133-3779-4466-aea4-3ab66c262002"
      },
      "source": [
        "**Currently, VertexAI Langchain does not support Codey Models. This code below is a custom wrapper for `code-bison` model. You can remove this code once, Langchain support VertexAI Codey models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bf11973-e610-4d7b-9217-8b4001132cbc",
      "metadata": {
        "id": "3bf11973-e610-4d7b-9217-8b4001132cbc"
      },
      "outputs": [],
      "source": [
        "\"\"\"Wrapper around Google VertexAI Codey models.\"\"\"\n",
        "from typing import TYPE_CHECKING, Any, Dict, List, Optional\n",
        "\n",
        "from pydantic import BaseModel, root_validator\n",
        "\n",
        "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain.llms.base import LLM\n",
        "from langchain.llms.utils import enforce_stop_tokens\n",
        "from langchain.utilities.vertexai import (\n",
        "    init_vertexai,\n",
        "    raise_vertex_import_error,\n",
        ")\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform.gapic.schema import predict\n",
        "from google.protobuf import json_format\n",
        "from google.protobuf.struct_pb2 import Value\n",
        "\n",
        "if TYPE_CHECKING:\n",
        "    from vertexai.language_models._language_models import _LanguageModel\n",
        "\n",
        "\n",
        "class _VertexAICommon(BaseModel):\n",
        "    client: \"_LanguageModel\" = None  #: :meta private:\n",
        "    model_name: str\n",
        "    \"Model name to use.\"\n",
        "    temperature: float = 0.0\n",
        "    \"Sampling temperature, it controls the degree of randomness in token selection.\"\n",
        "    max_output_tokens: int = 128\n",
        "    \"Token limit determines the maximum amount of text output from one prompt.\"\n",
        "    top_p: float = 0.95\n",
        "    \"Tokens are selected from most probable to least until the sum of their \"\n",
        "    \"probabilities equals the top-p value.\"\n",
        "    top_k: int = 40\n",
        "    \"How the model selects tokens for output, the next token is selected from \"\n",
        "    \"among the top-k most probable tokens.\"\n",
        "    stop: Optional[List[str]] = None\n",
        "    \"Optional list of stop words to use when generating.\"\n",
        "    project: Optional[str] = None\n",
        "    \"The default GCP project to use when making Vertex API calls.\"\n",
        "    location: str = \"us-central1\"\n",
        "    \"The default location to use when making API calls.\"\n",
        "    credentials: Any = None\n",
        "    \"The default custom credentials (google.auth.credentials.Credentials) to use \"\n",
        "    \"when making API calls. If not provided, credentials will be ascertained from \"\n",
        "    \"the environment.\"\n",
        "\n",
        "    @property\n",
        "    def _default_params(self) -> Dict[str, Any]:\n",
        "        base_params = {\n",
        "            \"temperature\": self.temperature,\n",
        "            \"max_output_tokens\": self.max_output_tokens,\n",
        "            \"top_k\": self.top_k,\n",
        "            \"top_p\": self.top_p,\n",
        "        }\n",
        "        return {**base_params}\n",
        "\n",
        "    def _predict(\n",
        "        self, prompt: str, stop: Optional[List[str]] = None, **kwargs: Any\n",
        "    ) -> str:\n",
        "        instance_dict = {\"prefix\": prompt}\n",
        "        instance = json_format.ParseDict(instance_dict, Value())\n",
        "        instances = [instance]\n",
        "        parameters_dict = {\n",
        "            \"temperature\": self.temperature,\n",
        "            \"max_output_tokens\": self.max_output_tokens,\n",
        "            \"top_k\": self.top_k,\n",
        "            \"top_p\": self.top_p,\n",
        "        }\n",
        "        parameters = json_format.ParseDict(parameters_dict, Value())\n",
        "        res = self.client.predict(\n",
        "          endpoint=self.model_name, instances=instances, parameters=parameters\n",
        "        )\n",
        "        return self._enforce_stop_words(res.predictions[0][\"content\"], stop)\n",
        "\n",
        "    def _enforce_stop_words(self, text: str, stop: Optional[List[str]] = None) -> str:\n",
        "        if stop is None and self.stop is not None:\n",
        "            stop = self.stop\n",
        "        if stop:\n",
        "            return enforce_stop_tokens(text, stop)\n",
        "        return text\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"vertexai\"\n",
        "\n",
        "    @classmethod\n",
        "    def _try_init_vertexai(cls, values: Dict) -> None:\n",
        "        allowed_params = [\"project\", \"location\", \"credentials\"]\n",
        "        params = {k: v for k, v in values.items() if k in allowed_params}\n",
        "        init_vertexai(**params)\n",
        "        return None\n",
        "\n",
        "\n",
        "class VertexAICode(_VertexAICommon, LLM):\n",
        "    \"\"\"Wrapper around Google Vertex AI large language models.\"\"\"\n",
        "\n",
        "    model_name: str = \"projects/workshop-trvlk/locations/us-central1/publishers/google/models/code-bison@001\"\n",
        "    tuned_model_name: Optional[str] = None\n",
        "    \"The name of a tuned model, if it's provided, model_name is ignored.\"\n",
        "\n",
        "    @root_validator()\n",
        "    def validate_environment(cls, values: Dict) -> Dict:\n",
        "        \"\"\"Validate that the python package exists in environment.\"\"\"\n",
        "        cls._try_init_vertexai(values)\n",
        "        try:\n",
        "            from vertexai.preview.language_models import TextGenerationModel\n",
        "        except ImportError:\n",
        "            raise_vertex_import_error()\n",
        "        client_options = {\"api_endpoint\": \"us-central1-aiplatform.googleapis.com\"}\n",
        "        # Initialize client that will be used to create and send requests.\n",
        "        # This client only needs to be created once, and can be reused for multiple requests.\n",
        "        values[\"client\"] = aiplatform.gapic.PredictionServiceClient(\n",
        "          client_options=client_options\n",
        "        )\n",
        "        return values\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> str:\n",
        "        \"\"\"Call Vertex model to get predictions based on the prompt.\n",
        "        Args:\n",
        "            prompt: The prompt to pass into the model.\n",
        "            stop: A list of stop words (optional).\n",
        "            run_manager: A Callbackmanager for LLM run, optional.\n",
        "        Returns:\n",
        "            The string generated by the model.\n",
        "        \"\"\"\n",
        "        return self._predict(prompt, stop, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5945f4b2-fae8-4f63-b44e-340409f4d8ca",
      "metadata": {
        "id": "5945f4b2-fae8-4f63-b44e-340409f4d8ca"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain.graphs import Neo4jGraph\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"You are an expert Neo4j Cypher translator who understands the question in english and convert to Cypher strictly based on the Neo4j Schema provided and following the instructions below:\n",
        "1. Generate Cypher query compatible ONLY for Neo4j Version 5\n",
        "2. Do not use EXISTS, SIZE keywords in the cypher. Use alias when using the WITH keyword\n",
        "3. Use only Nodes and relationships mentioned in the schema\n",
        "4. Always enclose the Cypher output inside 3 backticks\n",
        "5. Always do a case-insensitive and fuzzy search for any properties related search. Eg: to search for a Company name use `toLower(c.name) contains 'neo4j'`\n",
        "6. Candidate node is synonymous to Person\n",
        "7. Always use aliases to refer the node in the query\n",
        "8. Cypher is NOT SQL. So, do not mix and match the syntaxes\n",
        "Schema:\n",
        "{schema}\n",
        "Samples:\n",
        "Question: How many expert java developers attend more than one universities?\n",
        "Answer: MATCH (p:Person)-[:HAS_SKILL]->(s:Skill), (p)-[:HAS_EDUCATION]->(e1:Education), (p)-[:HAS_EDUCATION]->(e2:Education) WHERE toLower(s.name) CONTAINS 'java' AND toLower(s.level) CONTAINS 'expert' AND e1.university <> e2.university RETURN COUNT(DISTINCT p)\n",
        "Question: Where do most candidates get educated?\n",
        "Answer: MATCH (p:Person)-[:HAS_EDUCATION]->(e:Education) RETURN e.university, count(e.university) as alumni ORDER BY alumni DESC LIMIT 1\n",
        "Question: How many people have worked as a Data Scientist in San Francisco?\n",
        "Answer: MATCH (p:Person)-[:HAS_POSITION]->(pos:Position) WHERE toLower(pos.title) CONTAINS 'data scientist' AND toLower(pos.location) CONTAINS 'san francisco' RETURN COUNT(p)\n",
        "Question: {question}\n",
        "Answer:\n",
        "\"\"\"\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
        ")\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=connectionUrl,\n",
        "    username='neo4j',\n",
        "    password=password\n",
        ")\n",
        "chain = GraphCypherQAChain.from_llm(\n",
        "    VertexAICode(model_name='projects/workshop-trvlk/locations/us-central1/publishers/google/models/code-bison@001',\n",
        "            max_output_tokens=2048,\n",
        "            temperature=0,\n",
        "            top_p=0.95,\n",
        "            top_k=0.40), graph=graph, verbose=True,\n",
        "            cypher_prompt=CYPHER_GENERATION_PROMPT,\n",
        "    return_intermediate_steps=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8795e6a9-fa92-4a5f-8cc5-44a20d89d142",
      "metadata": {
        "id": "8795e6a9-fa92-4a5f-8cc5-44a20d89d142"
      },
      "source": [
        "That's it! You can run the agent now. Simply provide the command in English. You get Cypher as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bacd47c-b9dc-4da3-9344-149b23665cb2",
      "metadata": {
        "id": "4bacd47c-b9dc-4da3-9344-149b23665cb2",
        "outputId": "bf1a7c3a-2a76-4355-b8a1-7137db819640",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.callbacks.manager:Error in on_chain_start callback: 'name'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "MATCH (p:Person)-[:HAS_SKILL]->(s:Skill)\n",
            "WHERE toLower(s.name) CONTAINS 'python' AND toLower(s.level) CONTAINS 'expert'\n",
            "RETURN COUNT(p)\n",
            "\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'COUNT(p)': 15}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "r = chain(\"\"\"How many experts do we have on python\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc336003-88d1-40ad-a634-94ccfe77ef8b",
      "metadata": {
        "id": "cc336003-88d1-40ad-a634-94ccfe77ef8b",
        "outputId": "d06aed1b-32d9-44ee-8050-314afefe5e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intermediate steps: [{'query': \"\\nMATCH (p:Person)-[:HAS_SKILL]->(s:Skill)\\nWHERE toLower(s.name) CONTAINS 'ms word' AND toLower(s.level) CONTAINS 'expert'\\nRETURN COUNT(p)\\n\"}, {'context': [{'COUNT(p)': 0}]}]\n",
            "Final answer: I don't know the answer to that question.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Intermediate steps: {r['intermediate_steps']}\")\n",
        "print(f\"Final answer: {r['result']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f0f2c16-16cb-41f0-b50c-a8047c1a1517",
      "metadata": {
        "id": "4f0f2c16-16cb-41f0-b50c-a8047c1a1517"
      },
      "source": [
        "### Chatbot!\n",
        "Time to build a chatbot. We will be using Gradio to quickly try out our chatbot that uses a base model. Once VertexLLM is integrated into Langchain, you will get support for adapter tuned model as well.\n",
        "\n",
        "Running the code below will render a chat widget. You can view the Cypher generated for your input below this rendering.\n",
        "\n",
        "Note - Due to quota limitations, you might see errors while submitting the input. You need to wait a while in between your queries.\n",
        "\n",
        "Some sample questions to try out:\n",
        "\n",
        "1. How many experts do we have on MS Word?\n",
        "5. Who went to most number of universities and how many did they go to?\n",
        "6. Where do most candidates get educated?\n",
        "7. How many people know Delphi?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a060728-90a7-48fd-a197-ecd099b887bc",
      "metadata": {
        "id": "2a060728-90a7-48fd-a197-ecd099b887bc",
        "outputId": "4269b20a-a051-4a43-a2f5-c136c13c8453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7865\n",
            "Running on public URL: https://3339520db8660f2624.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://3339520db8660f2624.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "MATCH (p:Person)-[:HAS_SKILL]->(s:Skill) WHERE toLower(s.name) CONTAINS 'python' RETURN count(p)\n",
            "\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'count(p)': 15}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages = True)\n",
        "llm = VertexAICode(model_name='projects/neo4jbusinessdev/locations/us-central1/publishers/google/models/code-bison@001',\n",
        "            max_output_tokens=2048,\n",
        "            temperature=0,\n",
        "            top_p=0.95,\n",
        "            top_k=0.40)\n",
        "agent_chain = chain\n",
        "def chat_response(input_text):\n",
        "    response = agent_chain.run(input_text)\n",
        "    return response\n",
        "\n",
        "interface = gr.Interface(fn = chat_response, inputs = \"text\", outputs = \"text\",\n",
        "                         description = \"Talent Finder Chatbot\")\n",
        "\n",
        "interface.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc3f9ec1-b87b-4eee-9462-2a4c45218d25",
      "metadata": {
        "id": "fc3f9ec1-b87b-4eee-9462-2a4c45218d25"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
    },
    "kernelspec": {
      "display_name": "py38 (Local)",
      "language": "python",
      "name": "local-py38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "toc-autonumbering": true,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "toc-showtags": false
  },
  "nbformat": 4,
  "nbformat_minor": 5
}